{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Day 28 - Class </h1>\n",
    "\n",
    "## Improving Algorithms\n",
    "\n",
    "Last class we saw that we can employee different techniques for improving the model accuracy (e.g. blending , boosting etc). We keep track of the model metrics (accuracy, tn, fn , etc etc) for each model and pick the one that's performing the best. For competitions, however this will not be good enough. We have to see approaches like blending to make a better algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose best hyperparameters with GridSearchCV\n",
    "\n",
    "Grid search is the process of performing hyper parameter tuning in order to determine the optimal values for a given model. This is significant as the performance of the entire model is based on the hyper parameter values specified.\n",
    "\n",
    "A cross validation process is performed in order to determine the hyper parameter value set which provides the best accuracy levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.random.randint(1,100,(100,5))\n",
    "y = np.random.randint(0,2,(100))\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   13.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "params_grid = { 'max_depth' : [3,None],\n",
    "\t\t'min_samples_split' : [2,3,10],\n",
    "\t\t'min_samples_leaf':[1,3,10],\n",
    "\t\t'bootstrap':[True,False],\n",
    "\t\t'criterion':['gini','entropy']}\n",
    "\n",
    "grid_search = GridSearchCV(rf_clf,params_grid,n_jobs=-1,cv=5,verbose=1,scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "grid_search.best_score_\n",
    "\n",
    "grid_search.best_estimator_.get_params()\n",
    "\n",
    "#print_score(grid_search, X_train, y_train, X_test, y_test, train=True)\n",
    "\n",
    "#print_score(grid_search, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation\n",
    "\n",
    "Generally, an error estimation for the model is made after training, better known as evaluation of residuals. In this process, a numerical estimate of the difference in predicted and original responses is done, also called the training error. However, this only gives us an idea about how well our model does on data used to train it. Now its possible that the model is underfitting or overfitting the data. So, the problem with this evaluation technique is that it does not give an indication of how well the learner will generalize to an independent/ unseen data set. Getting this idea about our model is known as Cross Validation.\n",
    "\n",
    "#### Holdout Method\n",
    "\n",
    "Now a basic remedy for this involves removing a part of the training data and using it to get predictions from the model trained on rest of the data. The error estimation then tells how our model is doing on unseen data or the validation set. This is a simple kind of cross validation technique, also known as the holdout method. Although this method doesn’t take any overhead to compute and is better than traditional validation, it still suffers from issues of high variance. This is because it is not certain which data points will end up in the validation set and the result might be entirely different for different sets.\n",
    "\n",
    "#### K-Fold Cross Validation\n",
    "\n",
    "As there is never enough data to train your model, removing a part of it for validation poses a problem of underfitting. By reducing the training data, we risk losing important patterns/ trends in data set, which in turn increases error induced by bias. So, what we require is a method that provides ample data for training the model and also leaves ample data for validation. K Fold cross validation does exactly that.\n",
    "\n",
    "In K Fold cross validation, the data is divided into k subsets. Now the holdout method is repeated k times, such that each time, one of the k subsets is used as the test set/ validation set and the other k-1 subsets are put together to form a training set. The error estimation is averaged over all k trials to get total effectiveness of our model. As can be seen, every data point gets to be in a validation set exactly once, and gets to be in a training set k-1 times. This significantly reduces bias as we are using most of the data for fitting, and also significantly reduces variance as most of the data is also being used in validation set. Interchanging the training and test sets also adds to the effectiveness of this method. As a general rule and empirical evidence, K = 5 or 10 is generally preferred, but nothing’s fixed and it can take any value.\n",
    "\n",
    "#### Stratified K-Fold Cross Validation\n",
    "\n",
    "In some cases, there may be a large imbalance in the response variables. For example, in dataset concerning price of houses, there might be large number of houses having high price. Or in case of classification, there might be several times more negative samples than positive samples. For such problems, a slight variation in the K Fold cross validation technique is made, such that each fold contains approximately the same percentage of samples of each target class as the complete set, or in case of prediction problems, the mean response value is approximately equal in all the folds. This variation is also known as Stratified K Fold.\n",
    "\n",
    "#### How it works ?\n",
    "Run cross fold validation and see how model is performing for each data splits. If the model is performing with more or less same level of accuracies across multiple splits, then that's a good model\n",
    "\n",
    "See the below example, cv = 10 for a datasize of 500 records means each split has 50 records and we run the train on 9 samples and test on remaining 1 sample and so on for each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4, 0.4, 0.5, 0.6, 0.5, 0.4, 0.5, 0.2, 0.7, 0.4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(rf_clf,X,y,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending\n",
    "\n",
    "There are different types of blending. One of them is explained in the previous class. The other type is explained below,\n",
    "\n",
    "- We train the model on 'n' algorithms\n",
    "- We take the average predictions of each algorithm and give that as the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Building\n",
    "    - Machine Learning Models\n",
    "    - Accuracy Score and hyper-parameter tuning\n",
    "    - Single model which give you highest accuracy is chosen\n",
    "    - deploy and we use this for prediction\n",
    "\n",
    "- Advanced users/kaggle competition\n",
    "    - Stacking models\n",
    "    - boosting\n",
    "    - use this models for predicting the feature observations\n",
    "    - trade-off between interpretability - accuracy (complex techniques such as stacking gives better accuracy but interpretability is lost)\n",
    "    - gridsearch\n",
    "    - Find optimized parameters for each algorithms\n",
    "    - stacking or boosting algorithms\n",
    "    - check for accuracy\n",
    "    - k-fold validation\n",
    "    - submit prediction once you have k fold validation values in similar ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "While we develop a model we have to select the features(predictors) that helps the most in predicting/classifying the y-variable. The technique to achieve this is called 'feature engineering'. We try to select the most important features and as well try to see if we can make the insignificant features as significant by applying some techniques\n",
    "\n",
    "\n",
    "1) Feature Importance - You can objectively estimate the usefulness of features.\n",
    "\n",
    "2) Feature Extraction - is a process of automatically reducing the dimensionality of these types of observations into a much smaller set that can be modelled.\n",
    "- PCA\n",
    "\n",
    "3) Feature Selection - addresses these problems by automatically selecting a subset that are most useful to the problem.\n",
    "- correlation\n",
    "- forward selection\n",
    "- backward elimination\n",
    "- stepwise selection\n",
    "- L1/L2 regularisation\n",
    "\n",
    "4) Feature Construction\n",
    "\n",
    "#### Topics\n",
    "- Feature Engineering\n",
    "- Forward Selection\n",
    "- Backward Elimination\n",
    "- Stepwise Selection\n",
    "- Lowvariance Method\n",
    "- PCA (Principal Component Analysis)\n",
    "- LDA (Linear Discriminant Analysis)\n",
    "- TSNE (T Student Neighbourhood Embedding)\n",
    "\n",
    "Objective - \n",
    "Identify the imporant columns using \n",
    "- forward selection\n",
    "\n",
    "\n",
    "    Step 1\n",
    "\n",
    "    The first step is very similar to that of backward elimination. Here, we select a significance level, or a P-value. And as you already know, significance level of 5%, or a P-value of 0.05 is common. So let’s stick with that.\n",
    "    \n",
    "    Step 2\n",
    "\n",
    "    This is a pretty tedious step. In this second step, we create a simple regression model for each feature we have in our dataset. So if there are 100 features, we create 100 simple linear regression models. So this could get a lot boring and complicated depending on the number of features in your dataset. But this is also one of the most import step in the process. And once we fit all the simple linear regression models, we calculate the P-value for all of them and identify the feature with the lowest P-value.\n",
    "    \n",
    "    Step 3\n",
    "\n",
    "    In the previous step, we identified the feature with the lowest P-value. We’ll add that feature to the simple linear regression models of all other features. So in the second step, we had simple regression models with one feature each. In this step, we’ll have one less linear regression model, but each of them will have two features. Once we do this, we’ll fit the models again and calculate the P-values.\n",
    "    \n",
    "    Step 4\n",
    "\n",
    "    In this step, we have the P-values of all the models we created in the previous step. We identify the feature with the lowest P-value again. We check if this lowest P-value is less than the significance level, or 0.05 in our example. If so, we’ll take that new feature and add it as a feature to all other models. So basically, we’re repeating step 3 with a new feature. We’ll continue this loop until the lowest P-value we get from a model is no longer less than the significance level. Once we reach this stage, we break the loop.\n",
    "\n",
    "- backward elimination\n",
    "<img src='img/backward-selection-01.png'/>\n",
    "- stepwise selection\n",
    "- lowvariance method\n",
    "\n",
    "Convert insignificant to significant\n",
    "- PCA (Principal Component Analysis)\n",
    "- LDA (Linear Discriminant Analysis)\n",
    "- TSNE (T Student Neighbour Embedding)\n",
    "- Transformations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Techniques\n",
    "<b>Drop missing data rows/columns</b>\n",
    "\n",
    "When there is a lot of missing data, then drop those rows/columns. There is not an optimum threshold for dropping but you can use 70% as an example value and try to drop the rows and columns which have missing values with higher than this threshold.\n",
    "\n",
    "<b>Imputation</b>\n",
    "\n",
    "When there is a lot of missing value , you can choose to fill them with an 'ideal' value. Ideal value could be,\n",
    "\n",
    "0 or median of the feature, it varies b/w use cases. Median is not sensitive to outliers, whereas mean is sensitive to outlier.\n",
    "\n",
    "Replacing the missing values with the maximum occurred value in a column is a good option for handling categorical columns. But if you think the values in the column are distributed uniformly and there is not a dominant value, imputing a category like “Other” might be more sensible, because in such a case, your imputation is likely to converge a random selection.\n",
    "\n",
    "<b>Outlier handling</b>\n",
    "\n",
    "Limit to plus/minus 3 standard deviations \n",
    "\n",
    "Or \n",
    "\n",
    "Use Z-scores\n",
    "\n",
    "Or\n",
    "\n",
    "Use quantiles\n",
    "\n",
    "<b>Binning</b>\n",
    "<pre>\n",
    "#Numerical Binning Example\n",
    "\n",
    "Value  -> Bin\n",
    "0-30   ->  Low       \n",
    "31-70  ->  Mid       \n",
    "71-100 ->  High\n",
    "\n",
    "#Categorical Binning Example\n",
    "Value  ->  Bin       \n",
    "Spain  ->  Europe      \n",
    "Italy  ->  Europe       \n",
    "Chile  ->  South America\n",
    "Brazil ->  South America\n",
    "</pre>\n",
    "\n",
    "The trade-off between performance and overfitting is the key point of the binning process. In my opinion, for numerical columns, except for some obvious overfitting cases, binning might be redundant for some kind of algorithms, due to its effect on model performance. Thus, assigning a general category to these less frequent values helps to keep the robustness of the model. For example, if your data size is 100,000 rows, it might be a good option to unite the labels with a count less than 100 to a new category like “Other”.\n",
    "\n",
    "\n",
    "<b> Log transormations </b>\n",
    "\n",
    "<b> Normalisation </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "Having a large number of dimensions in the feature space can mean that the volume of that space is very large, and in turn, the points that we have in that space (rows of data) often represent a small and non-representative sample.\n",
    "\n",
    "This can dramatically impact the performance of machine learning algorithms fit on data with many input features, generally referred to as the “curse of dimensionality.”\n",
    "\n",
    "#### Principal Component Analysis (PCA)\n",
    "\n",
    "Principal Component Analysis, or PCA, is a dimensionality-reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set.\n",
    "\n",
    "PCA is an unsupervised machine learning method that is used for dimensionality reduction. The main idea of principal component analysis (PCA) is to reduce the dimensionality of a data set consisting of many variables correlated with each other, either heavily or lightly, while retaining the variation present in the dataset, up to the maximum extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wt1</th>\n",
       "      <th>wt2</th>\n",
       "      <th>wt3</th>\n",
       "      <th>wt4</th>\n",
       "      <th>wt5</th>\n",
       "      <th>ko1</th>\n",
       "      <th>ko2</th>\n",
       "      <th>ko3</th>\n",
       "      <th>ko4</th>\n",
       "      <th>ko5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>gene1</td>\n",
       "      <td>793</td>\n",
       "      <td>805</td>\n",
       "      <td>765</td>\n",
       "      <td>826</td>\n",
       "      <td>811</td>\n",
       "      <td>923</td>\n",
       "      <td>948</td>\n",
       "      <td>907</td>\n",
       "      <td>906</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gene2</td>\n",
       "      <td>103</td>\n",
       "      <td>127</td>\n",
       "      <td>131</td>\n",
       "      <td>124</td>\n",
       "      <td>115</td>\n",
       "      <td>462</td>\n",
       "      <td>514</td>\n",
       "      <td>421</td>\n",
       "      <td>493</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gene3</td>\n",
       "      <td>88</td>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "      <td>75</td>\n",
       "      <td>295</td>\n",
       "      <td>302</td>\n",
       "      <td>317</td>\n",
       "      <td>293</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gene4</td>\n",
       "      <td>298</td>\n",
       "      <td>332</td>\n",
       "      <td>292</td>\n",
       "      <td>310</td>\n",
       "      <td>301</td>\n",
       "      <td>830</td>\n",
       "      <td>819</td>\n",
       "      <td>862</td>\n",
       "      <td>823</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gene5</td>\n",
       "      <td>763</td>\n",
       "      <td>756</td>\n",
       "      <td>768</td>\n",
       "      <td>742</td>\n",
       "      <td>769</td>\n",
       "      <td>853</td>\n",
       "      <td>814</td>\n",
       "      <td>862</td>\n",
       "      <td>840</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gene96</td>\n",
       "      <td>691</td>\n",
       "      <td>681</td>\n",
       "      <td>719</td>\n",
       "      <td>684</td>\n",
       "      <td>727</td>\n",
       "      <td>533</td>\n",
       "      <td>529</td>\n",
       "      <td>554</td>\n",
       "      <td>564</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gene97</td>\n",
       "      <td>516</td>\n",
       "      <td>542</td>\n",
       "      <td>569</td>\n",
       "      <td>538</td>\n",
       "      <td>514</td>\n",
       "      <td>551</td>\n",
       "      <td>541</td>\n",
       "      <td>527</td>\n",
       "      <td>537</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gene98</td>\n",
       "      <td>536</td>\n",
       "      <td>507</td>\n",
       "      <td>517</td>\n",
       "      <td>506</td>\n",
       "      <td>511</td>\n",
       "      <td>863</td>\n",
       "      <td>853</td>\n",
       "      <td>848</td>\n",
       "      <td>842</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gene99</td>\n",
       "      <td>164</td>\n",
       "      <td>159</td>\n",
       "      <td>198</td>\n",
       "      <td>185</td>\n",
       "      <td>179</td>\n",
       "      <td>801</td>\n",
       "      <td>722</td>\n",
       "      <td>713</td>\n",
       "      <td>747</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gene100</td>\n",
       "      <td>39</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>481</td>\n",
       "      <td>439</td>\n",
       "      <td>473</td>\n",
       "      <td>437</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         wt1  wt2  wt3  wt4  wt5  ko1  ko2  ko3  ko4  ko5\n",
       "gene1    793  805  765  826  811  923  948  907  906  964\n",
       "gene2    103  127  131  124  115  462  514  421  493  487\n",
       "gene3     88   83   78   83   75  295  302  317  293  318\n",
       "gene4    298  332  292  310  301  830  819  862  823  865\n",
       "gene5    763  756  768  742  769  853  814  862  840  778\n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "gene96   691  681  719  684  727  533  529  554  564  555\n",
       "gene97   516  542  569  538  514  551  541  527  537  566\n",
       "gene98   536  507  517  506  511  863  853  848  842  932\n",
       "gene99   164  159  198  185  179  801  722  713  747  738\n",
       "gene100   39   56   52   48   50  481  439  473  437  477\n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "genes = ['gene' + str(i) for i in range (1,101)]\n",
    "wt = ['wt' + str(i) for i in range(1,6)]\n",
    "ko = ['ko' + str(i) for i in range(1,6)]\n",
    "data = pd.DataFrame(columns = [*wt, *ko], index = genes)\n",
    "\n",
    "for gene in data.index:\n",
    "    data.loc[gene,'wt1':'wt5'] = np.random.poisson(lam=rd.randrange(10,1000), size=5)\n",
    "    data.loc[gene,'ko1':'ko5'] = np.random.poisson(lam=rd.randrange(10,1000), size=5)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled_data = preprocessing.scale(data.T)\n",
    "pca = PCA()\n",
    "pca.fit(scaled_data)\n",
    "pca_data = pca.transform(scaled_data)\n",
    "\n",
    "per_var = np.round(pca.explained_variance_ratio_*100,decimals=1)\n",
    "labels = ['PC' + str(x) for x in range(1,len(per_var)+1)]\n",
    "\n",
    "plt.bar(x=range(1,len(per_var)+1), height = per_var, tick_label=labels)\n",
    "plt.ylabel('Percentage of explained variance')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_df = pd.DataFrame(pca_data, index=[*wt, *ko], columns = labels)\n",
    "plt.scatter(pca_df.PC1, pca_df.PC2)\n",
    "plt.title('My PCA Graph')\n",
    "\n",
    "plt.xlabel('PCA - {0}%'.format(per_var[0]))\n",
    "plt.ylabel('PCA - {0}%'.format(per_var[1]))\n",
    "\n",
    "for sample in pca_df.index:\n",
    "    plt.annotate(sample, (pca_df.PC1.loc[sample], pca_df.PC2.loc[sample]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene39    0.107057\n",
      "gene86    0.107037\n",
      "gene30   -0.107034\n",
      "gene18    0.107025\n",
      "gene60   -0.107015\n",
      "gene85   -0.106994\n",
      "gene54    0.106990\n",
      "gene20   -0.106958\n",
      "gene79    0.106955\n",
      "gene62    0.106954\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "loading_scores = pd.Series(pca.components_[0],index=genes)\n",
    "sorted_loading_scores = loading_scores.abs().sort_values(ascending=False)\n",
    "top_10_genes = sorted_loading_scores[0:10].index.values\n",
    "print(loading_scores[top_10_genes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Discriminant Analysis(LDA)\n",
    "Linear Discriminant Analysis, or LDA, is a linear machine learning algorithm used for multi-class classification.\n",
    "\n",
    "It should not be confused with “Latent Dirichlet Allocation” (LDA), which is also a dimensionality reduction technique for text documents\n",
    "\n",
    "Linear Discriminant Analysis seeks to best separate (or discriminate) the samples in the training dataset by their class value. Specifically, the model seeks to find a linear combination of input variables that achieves the maximum separation for samples between classes (class centroids or means) and the minimum separation of samples within each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.182 (0.032)\n",
      ">2 0.235 (0.036)\n",
      ">3 0.267 (0.038)\n",
      ">4 0.303 (0.037)\n",
      ">5 0.314 (0.049)\n",
      ">6 0.314 (0.040)\n",
      ">7 0.329 (0.042)\n",
      ">8 0.343 (0.045)\n",
      ">9 0.358 (0.056)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare lda number of components with naive bayes algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7, n_classes=10)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tfor i in range(1,10):\n",
    "\t\tsteps = [('lda', LinearDiscriminantAnalysis(n_components=i)), ('m', GaussianNB())]\n",
    "\t\tmodels[str(i)] = Pipeline(steps=steps)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the difference between LDA and PCA for dimensionality reduction?\n",
    "\n",
    "Both LDA and PCA are linear transformation techniques: LDA is a supervised whereas PCA is unsupervised – PCA ignores class labels.\n",
    "\n",
    "We can picture PCA as a technique that finds the directions of maximal variance:\n",
    "<img src='img/pca-01.png'/>\n",
    "\n",
    "In contrast to PCA, LDA attempts to find a feature subspace that maximizes class separability (note that LD 2 would be a very bad linear discriminant in the figure above).\n",
    "<img src='img/lda-01.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://towardsdatascience.com/backward-elimination-for-feature-selection-in-machine-learning-c6a3a8f8cef4\n",
    "\n",
    "https://sebastianraschka.com/faq/docs/lda-vs-pca.html\n",
    "\n",
    "https://machinelearningmastery.com/linear-discriminant-analysis-for-dimensionality-reduction-in-python/"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
