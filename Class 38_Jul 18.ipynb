{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Motion detection\n",
    "- Cam scanner app\n",
    "    - Homography\n",
    "\n",
    "- YOLO: You Only Look Once(CNN)\n",
    "    - The person has mask or not\n",
    "    - Predicting disease types\n",
    "    - Predicting objects in a class room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cv2.VideoCapture"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "camera = cv2.VideoCapture(\"D:\\sanooj\\datascience\\data\\y2mate.com - LONDON WALK Oxford Street to Carnaby Street England_NyLF8nHIquM_144p.mp4\")\n",
    "type(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 256, 3) (144, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "ret,frame1 = camera.read()\n",
    "ret,frame2 = camera.read()\n",
    "\n",
    "print(frame1.shape, frame2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('image.jpg',frame1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through the entire video frame by frame and write the corresponding images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=0\n",
    "while camera.read():\n",
    "    cv2.imwrite('image'+str(frame)+'.jpg',frame1)\n",
    "    frame=frame+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    diff = cv2.absdiff(frame1,frame2)\n",
    "    gray = cv2.cvtColor(diff,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #GaussianBlur - enhances the colors in WHITE even more.. enhances the BLACK even more.. \n",
    "    # Increases the contrast of the black and white colors by using 5*5 filters\n",
    "    blue=cv2.GaussianBlur(gray,(5,5),0)\n",
    "    _,thresh = cv2.threshold(blur,100,255,cv2.THRESH_BINARY)\n",
    "    dilated = cv2.dilate(thresh,None,iteration=3)\n",
    "    contours = cv2.findContours(dilated,cv2.RETR_TREE,CV2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cam=cv2.VideoCapture(r\"C:\\Users\\91733\\Downloads\\race.mp4\")\n",
    "cam=cv2.VideoCapture(0)\n",
    "frame=0\n",
    "_,frame1=cam.read()\n",
    "_,frame2=cam.read()\n",
    "#print(frame1.shape,frame2.shape)\n",
    "while True:\n",
    "    diff =cv2.absdiff(frame1,frame2)\n",
    "    gray=cv2.cvtColor(diff,cv2.COLOR_BGR2GRAY)\n",
    "    blur=cv2.GaussianBlur(gray,(5,5),0)\n",
    "    _,thresh=cv2.threshold(blur,100,255,cv2.THRESH_BINARY)\n",
    "    dilated=cv2.dilate(thresh,None,iterations=3)\n",
    "    contours,_=cv2.findContours(dilated,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)  \n",
    "    for i in contours :\n",
    "        (x,y,w,h)=cv2.boundingRect(i)\n",
    "        \n",
    "        if cv2.contourArea(i)<4000:\n",
    "            continue \n",
    "        cv2.rectangle(frame1,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        cv2.putText(frame1,\"motion detected\",(10,10),cv2.FONT_HERSHEY_COMPLEX,2,(0,255,0),3)\n",
    "        print(\"loop breaking\")\n",
    "    cv2.imshow(\"image\",frame1)\n",
    "    frame2=frame1\n",
    "    _,frame2=cam.read()\n",
    "    if cv2.waitKey():\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey()\n",
    "cam.release()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentals of deeplearning by Nikhil Buduma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in contours: \n",
    " if cv2.contourArea(i) < 1000:\n",
    "    continue\n",
    " else:\n",
    "    cv2.rectangle(frame1,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    cv2.text(frame1,'motion detected',cv2.FONT_HERSHEY_COMPLEX)\n",
    "    cv2.imshow(frame1)\n",
    "    frame2=frame1\n",
    "    _,frame2=camera.read()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey()\n",
    "    camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tzutalin.github.io/labelImg/\n",
    "\n",
    "YOLO\n",
    "\n",
    "Step 1 : define a real time problem\n",
    "\n",
    "Step 2 : collect the data set (mask or no mask, pic of him and sent a mail to admin)\n",
    "- Capture frame by frame video\n",
    "- scrapping\n",
    "- fatkun batch downloader\n",
    "\n",
    "Step 3 : image augmentation, data augmentation(open cv, python)\n",
    "\n",
    "Step 4: labelling (labelmg)\n",
    "\n",
    "step 5: create our master dataset(label mg)\n",
    "\n",
    "Step 6: google collab training custom detection (python ubunty kernel)\n",
    "\n",
    "step 7: we download weight file(CNN)\n",
    "\n",
    "step 8: custom object detection (open cv code)\n",
    "\n",
    "<b> Motion Detection Sample Program </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# 0 means read from the web cam\n",
    "cap = cv2.VideoCapture(0)\n",
    "frame_width = int( cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "frame_height =int( cap.get( cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n",
    "\n",
    "out = cv2.VideoWriter(\"output.avi\", fourcc, 5.0, (1280,720))\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "ret, frame2 = cap.read()\n",
    "print(frame1.shape)\n",
    "while cap.isOpened():\n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "    dilated = cv2.dilate(thresh, None, iterations=3)\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "        if cv2.contourArea(contour) < 900:\n",
    "            continue\n",
    "        cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame1, \"Status: {}\".format('Movement'), (10, 20), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1, (0, 0, 255), 3)\n",
    "    #cv2.drawContours(frame1, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    image = cv2.resize(frame1, (1280,720))\n",
    "    out.write(image)\n",
    "    cv2.imshow(\"feed\", frame1)\n",
    "    frame1 = frame2\n",
    "    ret, frame2 = cap.read()\n",
    "\n",
    "    if cv2.waitKey(40) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer homography.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
